{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1066c4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4071617",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout,Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255aef96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Loading data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97021c29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#getting the data \n",
    "# importing pickled data \n",
    "sup_df=pd.read_pickle('Pickledfiles/cl_fs_imdb_df.pkl') \n",
    "#sup_df=sup_df[['feature_selected','label']] # cleaned and feature selected reviews \n",
    "#sup_df.shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf25b50",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwel high cartoon comedi ran time program s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homeless or houseless georg carlin state issu ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brilliant over act lesley ann warren best dram...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easili underr film inn brook cannon sure flaw ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typic mel brook film much le slapstick movi ac...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  bromwel high cartoon comedi ran time program s...   pos\n",
       "1  homeless or houseless georg carlin state issu ...   pos\n",
       "2  brilliant over act lesley ann warren best dram...   pos\n",
       "3  easili underr film inn brook cannon sure flaw ...   pos\n",
       "4  typic mel brook film much le slapstick movi ac...   pos"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b4dd31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea67dec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#getting the training data \n",
    "# importing pickled data \n",
    "train_df=pd.read_pickle('Pickledfiles/cl_train_df.pkl') \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e645a38",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f188a0d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#getting the test data \n",
    "# importing pickled data \n",
    "test_df=pd.read_pickle('Pickledfiles/cl_test_df.pkl') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f19fda8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e139cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Function to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786b252e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#since we are using cleaned data, only splitting is required.\n",
    "\n",
    "def review_split(text):\n",
    "    import string\n",
    "    return text.split() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480ee2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ba60f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# preparing data\n",
    "x = sup_df.review\n",
    "# encode the target strings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(sup_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65bb0087",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# preparing training data\n",
    "x_train = train_df.review\n",
    "# encode the target strings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9510e17d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# preparing testing data\n",
    "x_test = test_df.review\n",
    "# encode the target strings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_test = le.fit_transform(test_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "269f65f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in consolidated dataset: \n",
      "49576\n",
      "Number of unique words in Training dataset: \n",
      "24898\n",
      "Number of unique words in Testing dataset: \n",
      "24795\n"
     ]
    }
   ],
   "source": [
    "# Total number of unique words\n",
    "print(\"Number of unique words in consolidated dataset: \")\n",
    "print(len(np.unique(np.hstack(x))))\n",
    "print(\"Number of unique words in Training dataset: \")\n",
    "print(len(np.unique(np.hstack(x_train))))\n",
    "print(\"Number of unique words in Testing dataset: \")\n",
    "print(len(np.unique(np.hstack(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb85a68b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        high cartoon comedi ran time program school li...\n",
       "1        or georg state issu year never plan help stree...\n",
       "2        brilliant over act ann best dramat ladi ever s...\n",
       "3        easili underr film brook sure flaw give realis...\n",
       "4        typic brook film much le slapstick movi actual...\n",
       "                               ...                        \n",
       "24995    toward end movi felt technic felt like watch p...\n",
       "24996    kind movi enemi content watch time bloodi true...\n",
       "24997    saw last night film festiv one huge disappoint...\n",
       "24998    film pick pound turn rather good rd centuri fi...\n",
       "24999    one dumbest film ive ever seen rip near ever t...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2b566",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assign Train and Test Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "357272b1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000 50000\n"
     ]
    }
   ],
   "source": [
    "msg_train = x_train\n",
    "msg_test = x_test\n",
    "label_train = y_train\n",
    "label_test = y_test\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6080502c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7bb21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Function to get maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07417cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1572c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Encode Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd257801",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[ 136  787  113 ...    0    0    0]\n",
      " [ 493  642  557 ... 2317 2303  109]\n",
      " [ 430  377   33 ...    0    0    0]\n",
      " ...\n",
      " [ 147  144  236 ...  138  165 2195]\n",
      " [   2  549 2524 ...    0    0    0]\n",
      " [   3 2991    2 ...    0    0    0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[ 425  147    1 ...    0    0    0]\n",
      " [  47  101   71 ...  529  206 1377]\n",
      " [1638 1377  454 ...    0    0    0]\n",
      " ...\n",
      " [ 426  448  571 ... 1668   10  412]\n",
      " [ 658   36 1026 ...    0    0    0]\n",
      " [ 584  355  325 ...   97 1038 1033]] \n",
      "\n",
      "Maximum review length:  106\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    \n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5f262",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Architetcure of LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78057c12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 106, 32)           96032     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 106, 32)           8320      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 106, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3392)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 250)               848250    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 952,853\n",
      "Trainable params: 952,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length=max_length))\n",
    "model.add((LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1585597",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use chekcpoint to save the epoch details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cac6187c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h50',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bead2018",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "196/196 [==============================] - 14s 67ms/step - loss: 0.3942 - accuracy: 0.8158\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.81576, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.2782 - accuracy: 0.8868\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.81576 to 0.88676, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 0.2359 - accuracy: 0.9067\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.88676 to 0.90672, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.1838 - accuracy: 0.9301\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.90672 to 0.93008, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "196/196 [==============================] - 14s 69ms/step - loss: 0.1299 - accuracy: 0.9517\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.93008 to 0.95168, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 0.0804 - accuracy: 0.9710\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.95168 to 0.97100, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "196/196 [==============================] - 14s 69ms/step - loss: 0.0492 - accuracy: 0.9828\n",
      "\n",
      "Epoch 00007: accuracy improved from 0.97100 to 0.98280, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 0.0337 - accuracy: 0.9884\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.98280 to 0.98840, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 0.0312 - accuracy: 0.9888\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.98840 to 0.98884, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "196/196 [==============================] - 14s 69ms/step - loss: 0.0288 - accuracy: 0.9896\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.98884 to 0.98964, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "196/196 [==============================] - 14s 69ms/step - loss: 0.0182 - accuracy: 0.9940\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.98964 to 0.99400, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 0.0113 - accuracy: 0.9959\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.99400 to 0.99592, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "196/196 [==============================] - 13s 66ms/step - loss: 0.0131 - accuracy: 0.9961\n",
      "\n",
      "Epoch 00013: accuracy improved from 0.99592 to 0.99608, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.0194 - accuracy: 0.9931\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.99608\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 14s 71ms/step - loss: 0.0213 - accuracy: 0.9925\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.99608\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 14s 71ms/step - loss: 0.0157 - accuracy: 0.9945\n",
      "\n",
      "Epoch 00016: accuracy did not improve from 0.99608\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.0136 - accuracy: 0.9952\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.99608\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "\n",
      "Epoch 00018: accuracy improved from 0.99608 to 0.99704, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.99704\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0130 - accuracy: 0.9959\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.99704\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 13s 69ms/step - loss: 0.0081 - accuracy: 0.9973\n",
      "\n",
      "Epoch 00021: accuracy improved from 0.99704 to 0.99728, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00022: accuracy improved from 0.99728 to 0.99800, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0086 - accuracy: 0.9972\n",
      "\n",
      "Epoch 00023: accuracy did not improve from 0.99800\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.0155 - accuracy: 0.9946\n",
      "\n",
      "Epoch 00024: accuracy did not improve from 0.99800\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 14s 69ms/step - loss: 0.0104 - accuracy: 0.9962\n",
      "\n",
      "Epoch 00025: accuracy did not improve from 0.99800\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 14s 69ms/step - loss: 0.0103 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.99800\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.0093 - accuracy: 0.9968\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.99800\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.0095 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.99800\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0084 - accuracy: 0.9969\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.99800\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0058 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.99800\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 13s 68ms/step - loss: 0.0035 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00031: accuracy improved from 0.99800 to 0.99892, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00032: accuracy did not improve from 0.99892\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00033: accuracy did not improve from 0.99892\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0103 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00034: accuracy did not improve from 0.99892\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 0.0087 - accuracy: 0.9968\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.99892\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00036: accuracy did not improve from 0.99892\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "\n",
      "Epoch 00037: accuracy did not improve from 0.99892\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00038: accuracy did not improve from 0.99892\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.99892\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "\n",
      "Epoch 00040: accuracy improved from 0.99892 to 0.99932, saving model to models\\LSTM.h50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\LSTM.h50\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0028 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00041: accuracy did not improve from 0.99932\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.0062 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00042: accuracy did not improve from 0.99932\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0087 - accuracy: 0.9973\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.99932\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.99932\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00045: accuracy did not improve from 0.99932\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 16s 84ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00046: accuracy did not improve from 0.99932\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0073 - accuracy: 0.9972\n",
      "\n",
      "Epoch 00047: accuracy did not improve from 0.99932\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.99932\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0039 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00049: accuracy did not improve from 0.99932\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 16s 83ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.99932\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train, y_train, batch_size = 128, epochs = 50, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc9daa8c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.64%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Accuracy: {scores[1]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338e26e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## End of Part 3 ##"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
